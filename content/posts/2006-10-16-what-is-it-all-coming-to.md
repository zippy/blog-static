---
title: "What is it all coming to?"
date: 2006-10-16
categories: 
  - "non-geeky"
  - "random"
slug: "what-is-it-all-coming-to"
---

Well, Bruce Sterling, as usual, has [an idea](http://www.newscientist.com/article/mg19125691.800-ii-saw-the-best-minds-of-my-generation-destroyed-by-googlei.html). It seems to me that we are walking a knife edge, nay, a ceramic blade edge of incredible sharpness, on one side of which is evolved conciousness, and the other, dismal slavery. That blade hurts my feet.

<div class="historical-comments mt-8 pt-8 border-t border-neutral-200 dark:border-neutral-700">
<h2 class="text-xl font-bold mb-4">Historical Comments</h2>
<div class="comment mb-6 p-4 bg-neutral-100 dark:bg-neutral-700 rounded-lg">
<div class="comment-meta text-sm text-neutral-600 dark:text-neutral-400 mb-2">
<span class="font-semibold">francois</span>
 &mdash; November 04, 2006 at 01:41 PM
</div>
<div class="comment-content prose dark:prose-invert"><p>This is what Larry Lessig (&lt;a href=&quot;http://lessig.org/&quot; rel=&quot;nofollow&quot;&gt;http://lessig.org/&lt;/a&gt;) has been yelling about for a few years now. In his 1999 book &#x27;Code Is Law&#x27; (&lt;a href=&quot;http://www.code-is-law.org/&quot; rel=&quot;nofollow&quot;&gt;http://www.code-is-law.org/&lt;/a&gt;, ) he literally argued that the architecture we devise for our information systems are like laws that are directly enforceable. In the real world leniency is built in because full enforceability would be too difficult, expensive, unpractical, or unrealistic. This allows a certain degree of flexibility within which exceptions can have their space, thus avoiding suffocation by complete control over everything. However in the architecture of information systems we can ensure rules are followed whatever the situation. Such level of enforceability are not necessarily desirable, and an obvious example is in the domain of copyright and how computer systems can enforce them, leaving little or no space for fair use.<br>This is why the model of the commons is so crucial, especially where technology inserts itself in-between people&#x27;s relationships. A social network software which cannot be changed by its users is simply a new form of totalitarism (cybertotalitarism?). How about online marketplaces where participants can&#x27;t have a say in how the market should be operated, or where they can be excluded arbitrarily?</p><p>Let&#x27;s avoid bleeding our feet by holding the vision high for the new systems we are creating. Let&#x27;s give ourselves the tools we need in order to become responsible in our choices. But first, let&#x27;s give ourselves systems where choice is possible, otherwise how can we practice our responsibility?</p></div>
</div>
<div class="comment mb-6 p-4 bg-neutral-100 dark:bg-neutral-700 rounded-lg">
<div class="comment-meta text-sm text-neutral-600 dark:text-neutral-400 mb-2">
<span class="font-semibold">eric</span>
 &mdash; November 04, 2006 at 07:59 PM
</div>
<div class="comment-content prose dark:prose-invert"><p>FranÃ§ois,  this is a great comment.  I&#x27;ve often noticed in projects that I&#x27;ve worked on how the way we design the code ends up forcing human behavior and not always in the happiest ways.  I think.  One of the simplest most obvious indicators of how important an issue this is, is just to look at &quot;skins&quot; and how much people like the choice that they embody.  The really issue is to make that choice not just be &quot;skin&quot; deep, but go as far down into the code as possible.</p></div>
</div>
</div>
